{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import LogicalRegression\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir_path = os.path.join(os.getcwd(), 'vnexpress')\n",
    "categories = list()\n",
    "\n",
    "data = list()\n",
    "for directory in os.listdir(dir_path):\n",
    "#     print(directory)\n",
    "    if '.' not in directory:\n",
    "        list_file_path = os.path.join(dir_path, directory)\n",
    "        count = 0\n",
    "        for file_name in os.listdir(list_file_path):\n",
    "            data_dict = dict()\n",
    "            data_dict['file_name'] = file_name\n",
    "            data_dict['category'] = directory\n",
    "            file_path = os.path.join(list_file_path, file_name)\n",
    "            file = open(file_path,'r')\n",
    "            data_dict['data'] = file.read()\n",
    "            data.append(data_dict)\n",
    "data_df = pd.DataFrame(data)\n",
    "sample_df = data_df.sample(10000)\n",
    "train, test = train_test_split(sample_df, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training:700 -  testing: 300 \n",
      "\n",
      "tf-idf learning time: 0.273914098739624\n",
      "feature extraction time of training and testing dataset: 0.4811859130859375\n",
      "training (700, 16403)\n",
      "testing (300, 16403)\n",
      "Logistic Regression time: 0.521176815032959\n",
      "testing time: 0.02210688591003418\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     dulich       0.95      0.87      0.91        23\n",
      "    giaitri       0.87      0.93      0.90        28\n",
      "    giaoduc       0.81      0.89      0.85        28\n",
      "    khoahoc       0.97      0.85      0.90        39\n",
      "  kinhdoanh       0.86      0.90      0.88        21\n",
      "   otoxemay       0.94      0.85      0.89        20\n",
      "   phapluat       0.91      1.00      0.95        31\n",
      "      sohoa       0.96      0.89      0.92        27\n",
      "    thegioi       0.93      0.93      0.93        28\n",
      "    thethao       0.96      0.96      0.96        28\n",
      "     thoisu       0.83      0.89      0.86        27\n",
      "\n",
      "avg / total       0.91      0.91      0.91       300\n",
      "\n",
      "{'time_consume': {'tf_idf': 0.2739739418029785, 'training_classifer': 0.5212738513946533, 'feature_extraction': 0.4812459945678711, 'test_classifier': 0.022137880325317383}, 'precision': 0.90876148463289252, 'fscore': 0.90569006351358894, 'recall': 0.90568586003368601, 'vector_size': 16403, 'vectorizer': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.75, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=False,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)}\n",
      "training:3500 -  testing: 1500 \n",
      "\n",
      "tf-idf learning time: 2.3643598556518555\n",
      "feature extraction time of training and testing dataset: 2.702580213546753\n",
      "training (3500, 39162)\n",
      "testing (1500, 39162)\n",
      "Logistic Regression time: 3.7231109142303467\n",
      "testing time: 0.7058680057525635\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     dulich       0.93      0.91      0.92       124\n",
      "    giaitri       0.93      0.97      0.95       150\n",
      "    giaoduc       0.88      0.91      0.89       130\n",
      "    khoahoc       0.94      0.93      0.93       146\n",
      "  kinhdoanh       0.78      0.92      0.84       118\n",
      "   otoxemay       0.98      0.97      0.98       148\n",
      "   phapluat       0.95      0.95      0.95       132\n",
      "      sohoa       0.91      0.84      0.88       122\n",
      "    thegioi       0.91      0.89      0.90       140\n",
      "    thethao       0.97      0.99      0.98       146\n",
      "     thoisu       0.92      0.80      0.86       144\n",
      "\n",
      "avg / total       0.92      0.92      0.92      1500\n",
      "\n",
      "{'time_consume': {'tf_idf': 2.364435911178589, 'training_classifer': 3.7233290672302246, 'feature_extraction': 2.702639102935791, 'test_classifier': 0.7059650421142578}, 'precision': 0.91712223837019069, 'fscore': 0.9156913001558955, 'recall': 0.91649859449984517, 'vector_size': 39162, 'vectorizer': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.75, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=False,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)}\n",
      "training:7000 -  testing: 3000 \n",
      "\n",
      "tf-idf learning time: 3.1995818614959717\n",
      "feature extraction time of training and testing dataset: 3.4756340980529785\n",
      "training (7000, 57366)\n",
      "testing (3000, 57366)\n",
      "Logistic Regression time: 8.592795133590698\n",
      "testing time: 1.5512080192565918\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     dulich       0.94      0.94      0.94       251\n",
      "    giaitri       0.98      0.99      0.98       286\n",
      "    giaoduc       0.95      0.95      0.95       268\n",
      "    khoahoc       0.93      0.95      0.94       287\n",
      "  kinhdoanh       0.95      0.91      0.93       271\n",
      "   otoxemay       0.98      0.98      0.98       244\n",
      "   phapluat       0.95      0.93      0.94       281\n",
      "      sohoa       0.96      0.93      0.94       259\n",
      "    thegioi       0.94      0.94      0.94       308\n",
      "    thethao       0.99      0.99      0.99       293\n",
      "     thoisu       0.86      0.91      0.88       252\n",
      "\n",
      "avg / total       0.95      0.95      0.95      3000\n",
      "\n",
      "{'time_consume': {'tf_idf': 3.1997969150543213, 'training_classifer': 8.593780040740967, 'feature_extraction': 3.475705146789551, 'test_classifier': 1.5512971878051758}, 'precision': 0.94685779573080142, 'fscore': 0.9465551308021406, 'recall': 0.94653516793791903, 'vector_size': 57366, 'vectorizer': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.75, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=False,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)}\n",
      "training:10500 -  testing: 4500 \n",
      "\n",
      "tf-idf learning time: 3.440749168395996\n",
      "feature extraction time of training and testing dataset: 5.000753879547119\n",
      "training (10500, 70785)\n",
      "testing (4500, 70785)\n",
      "Logistic Regression time: 17.67406702041626\n",
      "testing time: 3.3550608158111572\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     dulich       0.95      0.94      0.95       397\n",
      "    giaitri       0.99      0.97      0.98       407\n",
      "    giaoduc       0.95      0.96      0.95       409\n",
      "    khoahoc       0.95      0.96      0.95       387\n",
      "  kinhdoanh       0.93      0.90      0.92       429\n",
      "   otoxemay       0.98      0.98      0.98       394\n",
      "   phapluat       0.95      0.95      0.95       444\n",
      "      sohoa       0.95      0.95      0.95       402\n",
      "    thegioi       0.96      0.97      0.96       438\n",
      "    thethao       0.99      1.00      0.99       404\n",
      "     thoisu       0.88      0.90      0.89       389\n",
      "\n",
      "avg / total       0.95      0.95      0.95      4500\n",
      "\n",
      "{'time_consume': {'tf_idf': 3.4408161640167236, 'training_classifer': 17.67548704147339, 'feature_extraction': 5.00083589553833, 'test_classifier': 3.355123996734619}, 'precision': 0.95287317182603604, 'fscore': 0.9528572166669167, 'recall': 0.95293229767071075, 'vector_size': 70785, 'vectorizer': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.75, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=False,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)}\n",
      "training:14000 -  testing: 6000 \n",
      "\n",
      "tf-idf learning time: 4.871788024902344\n",
      "feature extraction time of training and testing dataset: 6.752629995346069\n",
      "training (14000, 83351)\n",
      "testing (6000, 83351)\n",
      "Logistic Regression time: 29.84699296951294\n",
      "testing time: 5.911134958267212\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     dulich       0.96      0.93      0.94       514\n",
      "    giaitri       0.98      0.99      0.98       600\n",
      "    giaoduc       0.93      0.96      0.95       531\n",
      "    khoahoc       0.95      0.95      0.95       542\n",
      "  kinhdoanh       0.95      0.92      0.93       557\n",
      "   otoxemay       0.98      0.97      0.98       549\n",
      "   phapluat       0.96      0.95      0.96       541\n",
      "      sohoa       0.96      0.96      0.96       499\n",
      "    thegioi       0.95      0.97      0.96       561\n",
      "    thethao       0.99      1.00      1.00       603\n",
      "     thoisu       0.89      0.89      0.89       503\n",
      "\n",
      "avg / total       0.96      0.96      0.96      6000\n",
      "\n",
      "{'time_consume': {'tf_idf': 4.871860980987549, 'training_classifer': 29.848079919815063, 'feature_extraction': 6.7527008056640625, 'test_classifier': 5.912723064422607}, 'precision': 0.95467788068540571, 'fscore': 0.95446387993780479, 'recall': 0.95441552961803933, 'vector_size': 83351, 'vectorizer': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.75, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=False,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)}\n",
      "training:17500 -  testing: 7500 \n",
      "\n",
      "tf-idf learning time: 6.069437026977539\n",
      "feature extraction time of training and testing dataset: 8.56702208518982\n",
      "training (17500, 93870)\n",
      "testing (7500, 93870)\n",
      "Logistic Regression time: 38.054256200790405\n",
      "testing time: 9.787324905395508\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     dulich       0.94      0.95      0.94       646\n",
      "    giaitri       0.98      0.98      0.98       738\n",
      "    giaoduc       0.95      0.95      0.95       664\n",
      "    khoahoc       0.96      0.96      0.96       693\n",
      "  kinhdoanh       0.94      0.94      0.94       732\n",
      "   otoxemay       0.99      0.99      0.99       673\n",
      "   phapluat       0.95      0.96      0.96       677\n",
      "      sohoa       0.97      0.94      0.96       638\n",
      "    thegioi       0.96      0.96      0.96       672\n",
      "    thethao       1.00      0.99      1.00       726\n",
      "     thoisu       0.90      0.91      0.91       641\n",
      "\n",
      "avg / total       0.96      0.96      0.96      7500\n",
      "\n",
      "{'time_consume': {'tf_idf': 6.0695061683654785, 'training_classifer': 38.055397033691406, 'feature_extraction': 8.567092895507812, 'test_classifier': 9.78838300704956}, 'precision': 0.95737227557187843, 'fscore': 0.95726974055827152, 'recall': 0.95722322394778314, 'vector_size': 93870, 'vectorizer': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.75, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=False,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)}\n",
      "training:21000 -  testing: 9000 \n",
      "\n",
      "tf-idf learning time: 7.174519062042236\n",
      "feature extraction time of training and testing dataset: 10.088097095489502\n",
      "training (21000, 105732)\n",
      "testing (9000, 105732)\n",
      "Logistic Regression time: 47.06330704689026\n",
      "testing time: 13.497066020965576\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     dulich       0.96      0.95      0.95       722\n",
      "    giaitri       0.99      0.99      0.99       886\n",
      "    giaoduc       0.96      0.96      0.96       759\n",
      "    khoahoc       0.95      0.96      0.95       826\n",
      "  kinhdoanh       0.95      0.95      0.95       894\n",
      "   otoxemay       0.98      0.98      0.98       766\n",
      "   phapluat       0.96      0.95      0.95       832\n",
      "      sohoa       0.97      0.97      0.97       762\n",
      "    thegioi       0.97      0.96      0.97       862\n",
      "    thethao       1.00      1.00      1.00       915\n",
      "     thoisu       0.90      0.91      0.91       776\n",
      "\n",
      "avg / total       0.96      0.96      0.96      9000\n",
      "\n",
      "{'time_consume': {'tf_idf': 7.174588203430176, 'training_classifer': 47.06435585021973, 'feature_extraction': 10.088166952133179, 'test_classifier': 13.498291015625}, 'precision': 0.96123747362069778, 'fscore': 0.9612158054002321, 'recall': 0.96122001622171471, 'vector_size': 105732, 'vectorizer': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.75, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=False,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)}\n",
      "training:24500 -  testing: 10500 \n",
      "\n",
      "tf-idf learning time: 8.440984010696411\n",
      "feature extraction time of training and testing dataset: 11.809036016464233\n",
      "training (24500, 114921)\n",
      "testing (10500, 114921)\n",
      "Logistic Regression time: 60.57721400260925\n",
      "testing time: 18.158339977264404\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     dulich       0.96      0.94      0.95       854\n",
      "    giaitri       0.98      0.99      0.99      1000\n",
      "    giaoduc       0.95      0.95      0.95       922\n",
      "    khoahoc       0.96      0.96      0.96       993\n",
      "  kinhdoanh       0.96      0.95      0.95       975\n",
      "   otoxemay       0.99      0.99      0.99       895\n",
      "   phapluat       0.97      0.96      0.96      1051\n",
      "      sohoa       0.97      0.97      0.97       876\n",
      "    thegioi       0.96      0.97      0.96       961\n",
      "    thethao       0.99      1.00      0.99      1007\n",
      "     thoisu       0.91      0.92      0.91       966\n",
      "\n",
      "avg / total       0.96      0.96      0.96     10500\n",
      "\n",
      "{'time_consume': {'tf_idf': 8.441053867340088, 'training_classifer': 60.57832717895508, 'feature_extraction': 11.809120178222656, 'test_classifier': 18.159705877304077}, 'precision': 0.96258228415713021, 'fscore': 0.96250376464960996, 'recall': 0.96247789677558948, 'vector_size': 114921, 'vectorizer': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.75, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=False,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)}\n",
      "training:28000 -  testing: 12000 \n",
      "\n",
      "tf-idf learning time: 9.561161994934082\n",
      "feature extraction time of training and testing dataset: 14.377403974533081\n",
      "training (28000, 124714)\n",
      "testing (12000, 124714)\n",
      "Logistic Regression time: 74.23627400398254\n",
      "testing time: 22.29335594177246\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     dulich       0.95      0.96      0.95       996\n",
      "    giaitri       0.98      0.99      0.99      1166\n",
      "    giaoduc       0.96      0.97      0.96      1057\n",
      "    khoahoc       0.96      0.96      0.96      1091\n",
      "  kinhdoanh       0.96      0.95      0.95      1147\n",
      "   otoxemay       0.99      0.99      0.99      1045\n",
      "   phapluat       0.95      0.96      0.95      1114\n",
      "      sohoa       0.97      0.96      0.96      1008\n",
      "    thegioi       0.97      0.96      0.96      1169\n",
      "    thethao       1.00      1.00      1.00      1168\n",
      "     thoisu       0.91      0.90      0.91      1039\n",
      "\n",
      "avg / total       0.96      0.96      0.96     12000\n",
      "\n",
      "{'time_consume': {'tf_idf': 9.561239004135132, 'training_classifer': 74.23800706863403, 'feature_extraction': 14.377475023269653, 'test_classifier': 22.2945339679718}, 'precision': 0.96279609207134598, 'fscore': 0.96279228504660141, 'recall': 0.96281254415515249, 'vector_size': 124714, 'vectorizer': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.75, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=False,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)}\n",
      "training:31500 -  testing: 13500 \n",
      "\n",
      "tf-idf learning time: 10.828793048858643\n",
      "feature extraction time of training and testing dataset: 15.317018985748291\n",
      "training (31500, 133438)\n",
      "testing (13500, 133438)\n",
      "Logistic Regression time: 87.18369197845459\n",
      "testing time: 28.16550302505493\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     dulich       0.94      0.94      0.94      1112\n",
      "    giaitri       0.98      0.99      0.98      1290\n",
      "    giaoduc       0.96      0.96      0.96      1226\n",
      "    khoahoc       0.96      0.95      0.96      1265\n",
      "  kinhdoanh       0.95      0.95      0.95      1308\n",
      "   otoxemay       0.99      0.98      0.98      1186\n",
      "   phapluat       0.97      0.95      0.96      1297\n",
      "      sohoa       0.96      0.98      0.97      1147\n",
      "    thegioi       0.95      0.97      0.96      1264\n",
      "    thethao       1.00      0.99      1.00      1277\n",
      "     thoisu       0.91      0.91      0.91      1128\n",
      "\n",
      "avg / total       0.96      0.96      0.96     13500\n",
      "\n",
      "{'time_consume': {'tf_idf': 10.828864097595215, 'training_classifer': 87.18524098396301, 'feature_extraction': 15.31709098815918, 'test_classifier': 28.167457103729248}, 'precision': 0.9617291088698573, 'fscore': 0.96174790330162274, 'recall': 0.96180372923153279, 'vector_size': 133438, 'vectorizer': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.75, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=False,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)}\n"
     ]
    }
   ],
   "source": [
    "result_list = list()\n",
    "for sample_size in [1000,5000,10000,15000,20000,25000,30000,35000,40000,45000]:\n",
    "    result = LogicalRegression.logistic_regression(sample_size,data_df)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_df = pd."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
