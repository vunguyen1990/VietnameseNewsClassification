{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn import linear_model\n",
    "\n",
    "import tensorflow.python.platform\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir_path = os.path.join(os.getcwd(), 'tok_vnexpress')\n",
    "categories = list()\n",
    "\n",
    "data = list()\n",
    "\n",
    "for directory in os.listdir(dir_path):\n",
    "    i = 0\n",
    "    if '.' not in directory:\n",
    "        list_file_path = os.path.join(dir_path, directory)\n",
    "        count = 0\n",
    "        for file_name in os.listdir(list_file_path):\n",
    "            data_dict = dict()\n",
    "            data_dict['category'] = directory\n",
    "            file_path = os.path.join(list_file_path, file_name)\n",
    "            file = open(file_path,'r')\n",
    "            data_dict['data'] = file.read()\n",
    "            data.append(data_dict)\n",
    "            i = i + 1\n",
    "            if i == 300: ## For test, only get 100 document from each category\n",
    "                break\n",
    "\n",
    "data_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contents = data_df['data']\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5)\n",
    "data_vector = vectorizer.fit_transform(contents)\n",
    "\n",
    "data_contents = data_vector.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_category_to_number(category):\n",
    "    if category == \"the-thao\":\n",
    "        return 0\n",
    "    if category == \"du-lich\":\n",
    "        return 1\n",
    "    if category == \"khoa-hoc\":\n",
    "        return 2\n",
    "    if category == \"kinh-doanh\":\n",
    "        return 3\n",
    "    if category == \"giai-tri\":\n",
    "        return 4\n",
    "    if category == \"oto-xe-may\":\n",
    "        return 5\n",
    "    if category == \"thoi-su\":\n",
    "        return 6\n",
    "    if category == \"giao-duc\":\n",
    "        return 7\n",
    "    if category == \"the-gioi\":\n",
    "        return 8\n",
    "    if category == \"phap-luat\":\n",
    "        return 9\n",
    "    if category == \"so-hoa\":\n",
    "        return 10\n",
    "    \n",
    "    raise ValueError('Category ' + category + \"not in training set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_vectors = pd.DataFrame(data_contents)\n",
    "df_vectors['category'] = data_df['category'].apply(convert_category_to_number)\n",
    "df_vectors.to_csv(\"docs_to_vec.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.python.platform\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Global variables.\n",
    "NUM_LABELS = 11    # The number of labels.\n",
    "BATCH_SIZE = 100  # The number of training examples to use per training step.\n",
    "\n",
    "\n",
    "# Extract numpy representations of the labels and features given rows consisting of:\n",
    "#   label, feat_0, feat_1, ..., feat_n\n",
    "\n",
    "def extract_data(vector_df):\n",
    "\n",
    "    # Arrays to hold the labels and feature vectors.\n",
    "    labels = vector_df['category']\n",
    "    fvecs = vector_df.drop('category', 1)\n",
    "\n",
    "    # Convert the array of float arrays into a numpy float matrix.\n",
    "    fvecs_np = np.matrix(fvecs).astype(np.float32)\n",
    "\n",
    "    # Convert the array of int labels into a numpy array.\n",
    "    labels_np = np.array(labels).astype(dtype=np.uint8)\n",
    "    \n",
    "    # Convert the int numpy array into a one-hot matrix.\n",
    "    labels_onehot = (np.arange(NUM_LABELS) == labels_np[:, None]).astype(np.float32)\n",
    "    \n",
    "    # Return a pair of the feature matrix and the one-hot label matrix.\n",
    "\n",
    "    return fvecs_np,labels_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "    train_df_vector, test_df_vector = train_test_split(df_vectors, test_size = 0.3)\n",
    "    \n",
    "    # Extract it into numpy matrices.\n",
    "    train_data,train_labels = extract_data(train_df_vector)\n",
    "    test_data, test_labels = extract_data(test_df_vector)\n",
    "\n",
    "    # Get the shape of the training data.\n",
    "    train_size,num_features = train_data.shape\n",
    "\n",
    "\n",
    "    # This is where training samples and labels are fed to the graph.\n",
    "    # These placeholder nodes will be fed a batch of training data at each\n",
    "    # training step using the {feed_dict} argument to the Run() call below.\n",
    "    x = tf.placeholder(\"float\", shape=[None, num_features])\n",
    "    y_ = tf.placeholder(\"float\", shape=[None, NUM_LABELS])\n",
    "    \n",
    "    # These are the weights that inform how much each feature contributes to\n",
    "    # the classification.\n",
    "    W = tf.Variable(tf.zeros([num_features,NUM_LABELS]))\n",
    "    b = tf.Variable(tf.zeros([NUM_LABELS]))\n",
    "    y = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "\n",
    "    # Optimization.\n",
    "    cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "\n",
    "\n",
    "    # For the test data, hold the entire dataset in one constant node.\n",
    "    test_data_node = tf.constant(test_data)\n",
    "\n",
    "    # Evaluation.\n",
    "    predicted_class = tf.argmax(y,1);\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "    # Create a local session to run this computation.\n",
    "    with tf.Session() as s:\n",
    "\n",
    "        # Run all the initializers to prepare the trainable parameters.\n",
    "        tf.initialize_all_variables().run()\n",
    "        \n",
    "        # Iterate and train.\n",
    "        print(\"train_size: \", train_size)\n",
    "        print(\"batch size: \", BATCH_SIZE)\n",
    "        print(\"train_size // BATCH_SIZE: \", train_size // BATCH_SIZE)\n",
    "        for step in range(train_size):\n",
    "            offset = (step * BATCH_SIZE) % train_size\n",
    "\n",
    "            # get a batch of data\n",
    "            batch_data = train_data[offset:(offset + BATCH_SIZE), :]\n",
    "            batch_labels = train_labels[offset:(offset + BATCH_SIZE)]\n",
    "\n",
    "            # feed data into the model\n",
    "            train_step.run(feed_dict={x: batch_data, y_: batch_labels})\n",
    "            \n",
    "            \n",
    "        print (\"Accuracy:\", accuracy.eval(feed_dict={x: test_data, y_: test_labels}))\n",
    "        eval_fun = lambda X: predicted_class.eval(feed_dict={x:X}); \n",
    "        \n",
    "        predict_classes = predicted_class.eval(feed_dict={x:test_data})\n",
    "        actual_classes = test_labels.argmax(axis=1)\n",
    "        return predict_classes, actual_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-8636c6298405>:42: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "train_size:  2310\n",
      "batch size:  100\n",
      "train_size // BATCH_SIZE:  23\n",
      "Accuracy: 0.887879\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>85</td>\n",
       "      <td>91</td>\n",
       "      <td>105</td>\n",
       "      <td>91</td>\n",
       "      <td>78</td>\n",
       "      <td>88</td>\n",
       "      <td>83</td>\n",
       "      <td>101</td>\n",
       "      <td>85</td>\n",
       "      <td>101</td>\n",
       "      <td>82</td>\n",
       "      <td>990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0   0   1    2   3   4   5   6    7   8    9  10  All\n",
       "row_0                                                    \n",
       "0      84   0    0   0   0   1   1    0   0    0   0   86\n",
       "1       0  77    6   0   2   0   2    2   2    2   0   93\n",
       "2       0   1   83   1   0   1   0    1   1    0   0   88\n",
       "3       0   2    1  79   0   0   4    2   1    0   2   91\n",
       "4       0   1    0   0  70   0   0    1   0    0   1   73\n",
       "5       0   2    1   1   0  82   1    0   0    0   0   87\n",
       "6       0   4    2   6   0   0  63    1   0    3   1   80\n",
       "7       0   0    3   0   0   0   1   93   1    0   1   99\n",
       "8       1   2    6   1   6   0   0    1  76    1   0   94\n",
       "9       0   0    1   1   0   1  10    0   0   95   0  108\n",
       "10      0   2    2   2   0   3   1    0   4    0  77   91\n",
       "All    85  91  105  91  78  88  83  101  85  101  82  990"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_classes, actual_classes = run()\n",
    "pd.crosstab(actual_classes, predict_classes, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.88871050896623016, 0.88896688730036566, 0.88757961798423424, None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "precision_recall_fscore_support(actual_classes, predict_classes, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.98      0.98        86\n",
      "          1       0.85      0.83      0.84        93\n",
      "          2       0.79      0.94      0.86        88\n",
      "          3       0.87      0.87      0.87        91\n",
      "          4       0.90      0.96      0.93        73\n",
      "          5       0.93      0.94      0.94        87\n",
      "          6       0.76      0.79      0.77        80\n",
      "          7       0.92      0.94      0.93        99\n",
      "          8       0.89      0.81      0.85        94\n",
      "          9       0.94      0.88      0.91       108\n",
      "         10       0.94      0.85      0.89        91\n",
      "\n",
      "avg / total       0.89      0.89      0.89       990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm,metrics,model_selection\n",
    "print(metrics.classification_report(actual_classes, predict_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
