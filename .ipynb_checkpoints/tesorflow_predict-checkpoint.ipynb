{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn import linear_model\n",
    "import input_data\n",
    "\n",
    "import tensorflow.python.platform\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir_path = os.path.join(os.getcwd(), 'vnexpress')\n",
    "categories = list()\n",
    "\n",
    "data = list()\n",
    "\n",
    "for directory in os.listdir(dir_path):\n",
    "    i = 0\n",
    "    if '.' not in directory:\n",
    "        list_file_path = os.path.join(dir_path, directory)\n",
    "        count = 0\n",
    "        for file_name in os.listdir(list_file_path):\n",
    "            data_dict = dict()\n",
    "            data_dict['category'] = directory\n",
    "            file_path = os.path.join(list_file_path, file_name)\n",
    "            file = open(file_path,'r')\n",
    "            data_dict['data'] = file.read()\n",
    "            data.append(data_dict)\n",
    "            i = i + 1\n",
    "            if i == 100: ## For test, only get 100 document from each category\n",
    "                break\n",
    "\n",
    "data_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contents = data_df['data']\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5)\n",
    "data_vector = vectorizer.fit_transform(contents)\n",
    "\n",
    "data_contents = data_vector.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_category_to_number(category):\n",
    "    if category == \"the-thao\":\n",
    "        return 0\n",
    "    if category == \"du-lich\":\n",
    "        return 1\n",
    "    if category == \"khoa-hoc\":\n",
    "        return 2\n",
    "    if category == \"kinh-doanh\":\n",
    "        return 3\n",
    "    if category == \"giai-tri\":\n",
    "        return 4\n",
    "    if category == \"oto-xe-may\":\n",
    "        return 5\n",
    "    if category == \"thoi-su\":\n",
    "        return 6\n",
    "    if category == \"giao-duc\":\n",
    "        return 7\n",
    "    if category == \"the-gioi\":\n",
    "        return 8\n",
    "    if category == \"phap-luat\":\n",
    "        return 9\n",
    "    if category == \"so-hoa\":\n",
    "        return 10\n",
    "    \n",
    "    raise ValueError('Category ' + category + \"not in training set\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_vectors = pd.DataFrame(data_contents)\n",
    "df_vectors['category'] = data_df['category'].apply(convert_category_to_number)\n",
    "df_vectors.to_csv(\"docs_to_vec.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.python.platform\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Global variables.\n",
    "NUM_LABELS = 11    # The number of labels.\n",
    "BATCH_SIZE = 100  # The number of training examples to use per training step.\n",
    "\n",
    "\n",
    "# Extract numpy representations of the labels and features given rows consisting of:\n",
    "#   label, feat_0, feat_1, ..., feat_n\n",
    "\n",
    "def extract_data(vector_df):\n",
    "\n",
    "    # Arrays to hold the labels and feature vectors.\n",
    "    labels = vector_df['category']\n",
    "    fvecs = vector_df.drop('category', 1)\n",
    "\n",
    "    # Convert the array of float arrays into a numpy float matrix.\n",
    "    fvecs_np = np.matrix(fvecs).astype(np.float32)\n",
    "\n",
    "    # Convert the array of int labels into a numpy array.\n",
    "    labels_np = np.array(labels).astype(dtype=np.uint8)\n",
    "    \n",
    "    # Convert the int numpy array into a one-hot matrix.\n",
    "    labels_onehot = (np.arange(NUM_LABELS) == labels_np[:, None]).astype(np.float32)\n",
    "    \n",
    "    # Return a pair of the feature matrix and the one-hot label matrix.\n",
    "\n",
    "    return fvecs_np,labels_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "    train_df_vector, test_df_vector = train_test_split(df_vectors, test_size = 0.3)\n",
    "    \n",
    "    # Extract it into numpy matrices.\n",
    "    train_data,train_labels = extract_data(train_df_vector)\n",
    "    test_data, test_labels = extract_data(test_df_vector)\n",
    "\n",
    "    # Get the shape of the training data.\n",
    "    train_size,num_features = train_data.shape\n",
    "\n",
    "\n",
    "    # This is where training samples and labels are fed to the graph.\n",
    "    # These placeholder nodes will be fed a batch of training data at each\n",
    "    # training step using the {feed_dict} argument to the Run() call below.\n",
    "    x = tf.placeholder(\"float\", shape=[None, num_features])\n",
    "    y_ = tf.placeholder(\"float\", shape=[None, NUM_LABELS])\n",
    "    \n",
    "    # These are the weights that inform how much each feature contributes to\n",
    "    # the classification.\n",
    "    W = tf.Variable(tf.zeros([num_features,NUM_LABELS]))\n",
    "    b = tf.Variable(tf.zeros([NUM_LABELS]))\n",
    "    y = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "\n",
    "    # Optimization.\n",
    "    cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "\n",
    "\n",
    "    # For the test data, hold the entire dataset in one constant node.\n",
    "    test_data_node = tf.constant(test_data)\n",
    "\n",
    "    # Evaluation.\n",
    "    predicted_class = tf.argmax(y,1);\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "    # Create a local session to run this computation.\n",
    "    with tf.Session() as s:\n",
    "\n",
    "        # Run all the initializers to prepare the trainable parameters.\n",
    "        tf.initialize_all_variables().run()\n",
    "        \n",
    "        # Iterate and train.\n",
    "        print(\"train_size: \", train_size)\n",
    "        print(\"batch size: \", BATCH_SIZE)\n",
    "        print(\"train_size // BATCH_SIZE: \", train_size // BATCH_SIZE)\n",
    "        for step in range(train_size // BATCH_SIZE + 1 )\n",
    "            offset = (step * BATCH_SIZE) % train_size\n",
    "\n",
    "            # get a batch of data\n",
    "            batch_data = train_data[offset:(offset + BATCH_SIZE), :]\n",
    "            batch_labels = train_labels[offset:(offset + BATCH_SIZE)]\n",
    "\n",
    "            # feed data into the model\n",
    "            train_step.run(feed_dict={x: batch_data, y_: batch_labels})\n",
    "            \n",
    "            \n",
    "        print (\"Accuracy:\", accuracy.eval(feed_dict={x: test_data, y_: test_labels}))\n",
    "        eval_fun = lambda X: predicted_class.eval(feed_dict={x:X}); \n",
    "        \n",
    "        predict_classes = predicted_class.eval(feed_dict={x:test_data})\n",
    "        actual_classes = test_labels.argmax(axis=1)\n",
    "        return predict_classes, actual_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-52-ffb787a65167>:42: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "train_size:  770\n",
      "batch size:  100\n",
      "train_size // BATCH_SIZE:  7\n",
      "Accuracy: 0.887879\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>38</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "      <td>15</td>\n",
       "      <td>37</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0   0   1   2   3   4   5   6   7   8   9  10  All\n",
       "row_0                                                 \n",
       "0      32   0   0   0   0   0   1   0   0   0   0   33\n",
       "1       0  24   0   0   0   0   0   0   1   0   0   25\n",
       "2       0   0  28   0   0   0   0   0   1   0   1   30\n",
       "3       0   0   0  26   0   0   1   0   0   0   0   27\n",
       "4       0   0   0   1  28   0   0   0   0   0   0   29\n",
       "5       0   0   0   1   0  29   0   0   0   0   0   30\n",
       "6       0   1   2   1   0   1  21   0   1   0   0   27\n",
       "7       0   2   2   0   0   0   2  15   0   0   0   21\n",
       "8       0   0   3   0   2   0   0   0  30   1   0   36\n",
       "9       0   0   3   0   0   2   3   0   0  25   0   33\n",
       "10      0   0   0   0   0   0   0   0   4   0  35   39\n",
       "All    32  27  38  29  30  32  28  15  37  26  36  330"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_classes, actual_classes = run()\n",
    "pd.crosstab(actual_classes, predict_classes, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.89603977692680037, 0.88532596858615686, 0.88582800245544713, None)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "precision_recall_fscore_support(actual_classes, predict_classes, average='macro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
