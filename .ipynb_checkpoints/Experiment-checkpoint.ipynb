{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import random\n",
    "from sklearn import linear_model\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I - Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Get categories of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.join(os.getcwd(), 'vnexpress')\n",
    "categories = list()\n",
    "\n",
    "data = list()\n",
    "for directory in os.listdir(dir_path):\n",
    "#     print(directory)\n",
    "    if '.' not in directory:\n",
    "        list_file_path = os.path.join(dir_path, directory)\n",
    "        count = 0\n",
    "        for file_name in os.listdir(list_file_path):\n",
    "            data_dict = dict()\n",
    "            data_dict['category'] = directory\n",
    "            file_path = os.path.join(list_file_path, file_name)\n",
    "            file = open(file_path,'r')\n",
    "            data_dict['data'] = file.read()\n",
    "            data.append(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample 10000 items to training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(data)\n",
    "sample_df = data_df.sample(10000)\n",
    "train, test = train_test_split(sample_df, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data = train.data\n",
    "training_label = train.category\n",
    "testing_data = test.data\n",
    "testing_label = test.category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting tf-idf model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf-idf learning time: 2.3387908935546875\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5)\n",
    "vectorizer.fit(training_data)\n",
    "print(\"tf-idf learning time:\", time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.5, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting features for training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature extraction time of training and testing dataset: 3.980196952819824\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "training_matrix = vectorizer.transform(training_data)\n",
    "testing_matrix = vectorizer.transform(testing_data)\n",
    "print(\"feature extraction time of training and testing dataset:\", time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (7000, 56962)\n",
      "testing (3000, 56962)\n"
     ]
    }
   ],
   "source": [
    "print('training',training_matrix.shape)\n",
    "print('testing',training_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_vector = training_matrix.toarray()\n",
    "testing_vector = testing_matrix.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import (manifold, datasets, decomposition, ensemble,discriminant_analysis, random_projection)\n",
    "reducer = decomposition.FactorAnalysis(n_components = 1000)\n",
    "reducer.fit(training_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_vector_reduce = reducer.transform(training_vector)\n",
    "testing_vector_reduce = reducer.transform(testing_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification by Logistic Regression of Scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression time: 8.803112030029297\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "logreg = linear_model.LogisticRegression(C=1e5)\n",
    "logreg.fit(training_vector,training_label)\n",
    "print('Logistic Regression time:',time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing time: 1.897918939590454\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "predicted_result = logreg.predict(testing_vector)\n",
    "print(\"testing time:\", time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     dulich       0.95      0.94      0.94       250\n",
      "    giaitri       0.98      0.99      0.98       290\n",
      "    giaoduc       0.95      0.96      0.95       251\n",
      "    khoahoc       0.95      0.95      0.95       295\n",
      "  kinhdoanh       0.94      0.93      0.93       273\n",
      "   otoxemay       0.98      0.96      0.97       267\n",
      "   phapluat       0.94      0.94      0.94       296\n",
      "      sohoa       0.97      0.94      0.95       252\n",
      "    thegioi       0.95      0.96      0.95       262\n",
      "    thethao       0.98      1.00      0.99       295\n",
      "     thoisu       0.87      0.88      0.87       269\n",
      "\n",
      "avg / total       0.95      0.95      0.95      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm,metrics,model_selection\n",
    "print(metrics.classification_report(testing_label, predicted_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
